{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Import timeframe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49996, 6, 704)\n"
     ]
    }
   ],
   "source": [
    "games = np.load('/tmp/game_data.npy')\n",
    "print (games.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Look at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print(games[1][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49996, 2)\n"
     ]
    }
   ],
   "source": [
    "labels = np.load('/tmp/game_labels.npy')\n",
    "print (labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Separate train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49996, 6, 704)\n",
      "(49996, 6, 704)\n",
      "(44996, 6, 704)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#labels_binary_length_corrected = labels.reshape((300000, 2))\n",
    "labels_binary_length_corrected = labels\n",
    "\n",
    "number_of_features_to_use = games.shape[2]\n",
    "\n",
    "data = np.zeros((games.shape[0],games.shape[1], number_of_features_to_use))\n",
    "for i in range(games.shape[0]):\n",
    "    for j in range(games.shape[1]):\n",
    "        data[i, j] = games[i,j][:number_of_features_to_use]\n",
    "print (data.shape)\n",
    "\n",
    "\n",
    "num_train_examples = int(len(data) * 0.9)\n",
    "print(data.shape)\n",
    "x_train = data[:num_train_examples,:]\n",
    "y_train = labels_binary_length_corrected[:num_train_examples,:]\n",
    "x_test = data[num_train_examples:,:]\n",
    "y_test = labels_binary_length_corrected[num_train_examples:,:]\n",
    "\n",
    "#x_train = np.reshape(x_train, x_train.shape + (1,))\n",
    "#x_test = np.reshape(x_test, x_test.shape + (1,))\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.regularizers import l2\n",
    "import keras\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(\n",
    "    input_shape=(None, x_train.shape[2]),\n",
    "    units=800,\n",
    "    return_sequences=False,\n",
    "    kernel_regularizer= l2(0.01))\n",
    "    )\n",
    "\n",
    "model.add(Dense(\n",
    "    units=2))\n",
    "model.add(Activation('softmax'))\n",
    "#model.compile(loss='mse', optimizer='rmsprop')\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.RMSprop(lr=0.0001), metrics=[keras.metrics.mae, keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35996 samples, validate on 9000 samples\n",
      "Epoch 1/40\n",
      "12s - loss: 2.8091 - mean_absolute_error: 0.4673 - categorical_accuracy: 0.6089 - val_loss: 0.7798 - val_mean_absolute_error: 0.4484 - val_categorical_accuracy: 0.6384\n",
      "Epoch 2/40\n",
      "12s - loss: 0.7299 - mean_absolute_error: 0.4499 - categorical_accuracy: 0.6313 - val_loss: 0.6924 - val_mean_absolute_error: 0.4519 - val_categorical_accuracy: 0.6464\n",
      "Epoch 3/40\n",
      "12s - loss: 0.6799 - mean_absolute_error: 0.4465 - categorical_accuracy: 0.6379 - val_loss: 0.6667 - val_mean_absolute_error: 0.4466 - val_categorical_accuracy: 0.6438\n",
      "Epoch 4/40\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = keras.callbacks.ModelCheckpoint('/tmp/best_weights', monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "history = model.fit(x_train, y_train, epochs=40, batch_size=64, validation_split=0.2, verbose=2, callbacks = [model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.load_weights('/tmp/best_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Test loss and accuracy\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = model.predict_proba(x_test, verbose=0)\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove unsure predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(x_test, verbose=0)\n",
    "ind1 = y_pred[:,0] > 0.6\n",
    "ind2 = y_pred[:,1] > 0.6\n",
    "ind = ind1 + ind2\n",
    "y_pred2 = y_pred[ind]\n",
    "y_test2 = y_test[ind]\n",
    "x_test2 = x_test[ind]\n",
    "print(ind)\n",
    "print(y_pred2.shape)\n",
    "print(y_pred.shape)\n",
    "score = roc_auc_score(y_test2, y_pred2)\n",
    "print(score)\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test2, y_test2, verbose=2)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
